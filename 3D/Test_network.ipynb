{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from CO2_identify import *\n",
    "from labeling import *\n",
    "from mynetwork import CO2mask\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torchvision.transforms.functional import resize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../define_path.txt'\n",
    "with open(fn) as f:\n",
    "    lines = f.readlines()\n",
    "for idx, line in enumerate(lines):\n",
    "    if idx == 1:\n",
    "        dir_co2 = line.split('=')[1][:-1]\n",
    "    if idx == 11:\n",
    "        analpath = line.split('=')[1][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the testing data and testing network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the original testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file pathes\n",
    "blfn = f'{dir_co2}/94p10/2010 processing/data/94p10nea.sgy' # baseline data processed in 2010\n",
    "tlfn = f'{dir_co2}/10p10/2010 processing/data/10p10nea.sgy' # timelapse (2010) data processed in 2010\n",
    "mkfn = f'../resources/label/masks.dat' # CO2 masks interpreted from 1994 and 2010 data processed in 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data head\n",
    "D0 = dataload(fn=blfn)\n",
    "Dt = dataload(fn=tlfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the entire 3D data from the three data volume\n",
    "d0,xd,yd,td = D0.getdata()\n",
    "dt,_,_,_ = Dt.getdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d resize class\n",
    "RS = resize3d(1,D=64,H=64,W=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin CO2 mask\n",
    "masks = np.fromfile(f'{mkfn}',dtype=np.float32)\n",
    "masks = np.reshape(masks,(D0.nx,D0.ny,D0.nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select certain part of the original data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display objective inline section for baseline and time-lapse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inline section comparison\n",
    "InN = 130\n",
    "fig,ax = plt.subplots(1,2,figsize=(20,5))\n",
    "ax[0].imshow(d0[InN,:,:].T,aspect=0.5,cmap='gray')\n",
    "ax[1].imshow(dt[InN,:,:].T,aspect=0.5,cmap='gray')\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('Xline No.')\n",
    "    ax[i].set_ylabel('Time (2 ms)')\n",
    "    if i<1:\n",
    "        ax[i].set_title(f'1994 baseline, processed in 2010')\n",
    "    else:\n",
    "        ax[i].set_title(f'2010 time-lapse, processed in 2010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display objective trace for baseline and time-lapse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XnN = 245\n",
    "# trace comparison\n",
    "t1 = 0\n",
    "t2 = 1000\n",
    "fig,ax = plt.subplots(1,1,figsize=(15,5))\n",
    "ax.plot(d0[InN,XnN,:],label=f'baseline processed in 2010')\n",
    "ax.plot(dt[InN,XnN,:],label=f'time-lapse processed in 2010')\n",
    "ax.set_xlim(t1,t2)\n",
    "ax.set_xlabel('Time (2 ms)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine the sampling position for two cube centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = f'{analpath}/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ni,Nx,Nt = 128,128,256\n",
    "rs = [64,64,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Isample = [InN]\n",
    "Xsample = [XnN]\n",
    "Tsample = [450,850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate parameter csv\n",
    "pm_info = OrderedDict()\n",
    "pm_info['data_dim'] = [D0.nx,D0.ny,D0.nt] # [ensemble number,trace number per ensemble,sample number per trace]\n",
    "pm_info['data_path'] = [blfn,tlfn]\n",
    "pm_info['patch_osize'] = [Ni,Nx,Nt]\n",
    "pm_info['patch_nsize'] = rs\n",
    "pm_info['patch_number'] = 1\n",
    "pm_info['sample_strategy'] = 1\n",
    "pm_info['max_0co2'] = 0 # if none, means no limit for zero co2 masks\n",
    "with open(f'{outpath}/pm_info.json','w') as f:\n",
    "    f.write(json.dumps(pm_info))\n",
    "with open(f'{outpath}/pm_info.json','r') as read_file:\n",
    "    loaded_pm = json.loads(read_file.read())\n",
    "    print(loaded_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "hNi,hNx,hNt = Ni//2,Nx//2,Nt//2\n",
    "# sample the patches iteratively\n",
    "hNi1 = Ni-hNi\n",
    "hNx1 = Nx-hNx\n",
    "hNt1 = Nt-hNt\n",
    "patch_info = []\n",
    "c = 0\n",
    "for Is,Xs,Ts in product(Isample,Xsample,Tsample):\n",
    "    # slice the data\n",
    "    R0 = d0[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1]\n",
    "    Rt = dt[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1]\n",
    "    # slice the mask\n",
    "    M = np.array(masks[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1],dtype=np.float32)\n",
    "    M = RS.resize(torch.tensor(M).unsqueeze(0).unsqueeze(0),NP=True) # 5D: (N=1,C=1,D=128,H=128,W=128)\n",
    "    M.tofile(f'{outpath}/Mask_{c}.dat')\n",
    "    # normalize R0 and Rt respectively\n",
    "    Rm0,Rs0 = np.mean(R0),np.std(R0)\n",
    "    Rmt,Rst = np.mean(Rt),np.std(Rt)\n",
    "    R0 = (R0-Rm0)/(Rs0+eps)\n",
    "    Rt = (Rt-Rmt)/(Rst+eps)\n",
    "    # stack R0 and Rt\n",
    "    R0t = torch.tensor(np.stack((R0,Rt))).unsqueeze(0)\n",
    "    R0t = RS.resize(R0t,NP=True) # 5D: (N=1,C=2,D=64,H=64,W=64)\n",
    "    # save the patches and corresponding masks to outpath\n",
    "    R0t.tofile(f'{outpath}/R0t_{c}.dat')\n",
    "    # record the patch information in patch_info dict\n",
    "    pf = OrderedDict()\n",
    "    pf['Ptch_id'] = c\n",
    "    pf['Mask_id'] = c\n",
    "    pf['ct'] = [Is,Xs,Ts]\n",
    "    pf['mean'] = [Rm0,Rmt]\n",
    "    pf['std'] = [Rs0,Rst]\n",
    "    patch_info.append(pf)\n",
    "    c += 1\n",
    "# save the patch info\n",
    "pd.DataFrame.from_dict(patch_info, orient='columns').to_csv(f'{outpath}/patch_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the analysis dataset\n",
    "pmf = 'pm_info.json'\n",
    "pdf = 'patch_info.csv'\n",
    "analy = dataset_patch(outpath,pmf,pdf)\n",
    "Nana = len(analy)\n",
    "print(f'Training dataset size: {Nana}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the analysis dataset\n",
    "id_list = range(Nana)\n",
    "psa = patch_show(analy,id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revise the show slice index for psa the same\n",
    "psa.ixtid[0] = [32,32,32]\n",
    "for i in range(Nana):\n",
    "    psa.ixtid[i] = psa.ixtid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the testing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_net = f'../resources/NNpred3D/train_fulllabel/co2_identify_best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network\n",
    "networktest = CO2mask()\n",
    "networktest.load_state_dict(torch.load(path_net,map_location=torch.device('cpu')))\n",
    "networktest = networktest.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original test of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform testing\n",
    "loader_analy = DataLoader(\n",
    "     analy\n",
    "    ,batch_size = Nana)\n",
    "# allocate memory for testing batches\n",
    "Anpred = np.zeros((Nana,rs[0],rs[1],rs[2]))\n",
    "for batch in loader_analy:\n",
    "    R0t, Mr, _ = batch\n",
    "    # forward modeling\n",
    "    with torch.no_grad():\n",
    "        pMask = networktest(R0t)\n",
    "    # record the sampled testing patches for later display\n",
    "    Anpred = pMask.squeeze(1).cpu().detach().numpy()\n",
    "# display the patch fitting in the analysing dataset\n",
    "psa.view3d(Anpred,rcstride=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anpred.tofile(f'{outpath}/orgpred.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R0t_basic = torch.clone(R0t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output original R0 and Rt for display\n",
    "R0t.numpy().tofile(f'{outpath}/orgR0t.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift3D(d,ts):\n",
    "    r'''\n",
    "    dynamically shift d in 3D with 3D t:\n",
    "        d--3D float array (nx,ny,nt)\n",
    "        ts--same size as d\n",
    "    '''\n",
    "    nx,ny,nt = d.shape\n",
    "    hnt = (nt+1)//2\n",
    "    D = np.fft.fft(d,axis=2)\n",
    "    w = np.fft.fftfreq(nt,1)*2*pi\n",
    "    w = w[1:hnt]\n",
    "    t = np.arange(nt)\n",
    "    W = np.expand_dims(w,0)\n",
    "    T = np.expand_dims(t,1)\n",
    "    ds = np.zeros_like(d)\n",
    "    for i,j in product(range(nx),range(ny)):\n",
    "        Dij = np.expand_dims(D[i,j,1:hnt],0)\n",
    "        tsij = np.expand_dims(ts[i,j,:],1)\n",
    "        F = np.exp(1j*W*(T+tsij))\n",
    "        ds[i,j,:] = 2*np.sum((Dij*F).real,axis=1)+D[i,j,0].real\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale up the middle part of the multiple time-lapse image and the baseline image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path\n",
    "outpath0 = f'{analpath}/data_s0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = glob.glob(f'{outpath}/*')\n",
    "for fni in fn:\n",
    "    shutil.copy(fni, f'{outpath0}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the scalar\n",
    "s = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I1,I2 = 16,48\n",
    "X1,X2 = 16,48\n",
    "T1,T2 = 16,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = hanning3d((I2-I1,X2-X1,T2-T1),(0.2,0.2,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.ones(tuple(rs),dtype=np.float32)\n",
    "S[I1:I2,X1:X2,T1:T2] += H*(s-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show3D(S,xyzi=psa.ixtid[0],rcstride=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.tensor(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sb = torch.unsqueeze(torch.unsqueeze(S,0),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'''\n",
    "# time shift\n",
    "ts = np.zeros(tuple(rs),dtype=np.float32)\n",
    "for i,j in product(range(rs[0]),range(rs[1])):\n",
    "    ts[i,j,:] = np.cumsum(Sb[0,0,i,j].numpy()-1)*0.5/20\n",
    "show3D(ts,xyzi=psa.ixtid[0],rcstride=(2,2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the time-lapse multiple and the baseline, respectively\n",
    "# mutliple\n",
    "R0t[0,0] = R0t_basic[1,0]\n",
    "R0t[0,1] = R0t_basic[1,1]*Sb[0,0]\n",
    "#R0t[0,1] = torch.tensor(shift3D(R0t[0,1].numpy(),-ts))\n",
    "Rm,Rs = torch.mean(R0t[0,1]),torch.std(R0t[0,1])\n",
    "R0t[0,1] = (R0t[0,1]-Rm)/(Rs+eps)\n",
    "R0t[0].numpy().tofile(f'{outpath0}/R0t_{0}.dat')\n",
    "# baseline\n",
    "R0t[1,1] = R0t_basic[1,0]*Sb[0,0]\n",
    "#R0t[1,1] = torch.tensor(shift3D(R0t[1,1].numpy(),-ts))\n",
    "Rm,Rs = torch.mean(R0t[1,1]),torch.std(R0t[1,1])\n",
    "R0t[1,1] = (R0t[1,1]-Rm)/(Rs+eps)\n",
    "R0t[1].numpy().tofile(f'{outpath0}/R0t_{1}.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output S for display\n",
    "S.numpy().tofile(f'{outpath0}/scale.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output scaled Rt for display\n",
    "R0t.numpy().tofile(f'{outpath}/testR0t.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperform the testing on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the analysis dataset\n",
    "analy = dataset_patch(outpath0,pmf,pdf)\n",
    "Nana = len(analy)\n",
    "print(f'Training dataset size: {Nana}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for display the analysis dataset\n",
    "id_list = range(Nana)\n",
    "psa = patch_show(analy,id_list)\n",
    "# revise the show slice index for psa the same\n",
    "psa.ixtid[0] = [32,32,32]\n",
    "for i in range(Nana):\n",
    "    psa.ixtid[i] = psa.ixtid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform testing\n",
    "loader_analy = DataLoader(\n",
    "     analy\n",
    "    ,batch_size = Nana)\n",
    "# allocate memory for testing batches\n",
    "Anpred = np.zeros((Nana,rs[0],rs[1],rs[2]))\n",
    "for batch in loader_analy:\n",
    "    R0t, Mr, _ = batch\n",
    "    # forward modeling\n",
    "    with torch.no_grad():\n",
    "        pMask = networktest(R0t)\n",
    "    # record the sampled testing patches for later display\n",
    "    Anpred = pMask.squeeze(1).cpu().detach().numpy()\n",
    "# display the patch fitting in the analysing dataset\n",
    "psa.view3d(Anpred,rcstride=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anpred.tofile(f'{outpath0}/testpred.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace comparison\n",
    "I,X,_ = psa.ixtid[0]\n",
    "ylim = [-6,6]\n",
    "fig,ax = plt.subplots(1,2,figsize=(20,5))\n",
    "ax[0].plot(R0t[0,0,I,X,:],label=f'94p10, primary')\n",
    "ax[0].plot(R0t[0,1,I,X,:],label=f'10p10, primary')\n",
    "ax[1].plot(R0t[1,0,I,X,:],label=f'94p10, multiple')\n",
    "ax[1].plot(R0t[1,1,I,X,:],label=f'10p10, multiple')\n",
    "for i in range(2):\n",
    "    ax[i].set_xlim(0,rs[2])\n",
    "    ax[i].set_ylim(ylim[0],ylim[1])\n",
    "    ax[i].set_xlabel('Time (2 ms)')\n",
    "    ax[i].set_ylabel('Amplitude')\n",
    "    ax[i].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.433px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
