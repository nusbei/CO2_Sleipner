{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from labeling import *\n",
    "from CO2_identify import resize3d, mute_top\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../define_path.txt'\n",
    "with open(fn) as f:\n",
    "    lines = f.readlines()\n",
    "for idx, line in enumerate(lines):\n",
    "    if idx == 1:\n",
    "        dir_co2 = line.split('=')[1][:-1]\n",
    "    if idx == 3:\n",
    "        dir_grid = line.split('=')[1][:-1]\n",
    "    if idx == 5:\n",
    "        outpath0 = line.split('=')[1][:-1]\n",
    "    if idx == 7:\n",
    "        outpath = line.split('=')[1][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Basic pathes for baseline data and time-lapse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file pathes\n",
    "blfn = f'{dir_co2}/94p10/2010 processing/data/94p10nea.sgy' # baseline data processed in 2010\n",
    "blfn2 = f'{dir_co2}/94p01/2001 processing/data/94p01nea.sgy' # baseline data processed in 2001\n",
    "tlfn = f'{dir_co2}/10p10/2010 processing/data/10p10nea.sgy' # timelapse (2010) data processed in 2010\n",
    "tlfn2 = f'{dir_co2}/10p11/2011 processing/data/10p11nea' # timelapse (2011) data processed in 2011\n",
    "mkfn = f'../resources/label/masks.dat' # CO2 masks interpreted from 1994 and 2010 data processed in 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trace number: 150909\n",
      "Sample number along each trace: 1001\n",
      "Sampling interval along each trace: 0.002 s\n",
      "data arrangement: 269 (number of ensembles) x 561 (trace number per ensemble) x 1001 (sample number per trace)\n",
      "Total trace number: 166747\n",
      "Sample number along each trace: 1001\n",
      "Sampling interval along each trace: 0.002 s\n",
      "data arrangement: 287 (number of ensembles) x 581 (trace number per ensemble) x 1001 (sample number per trace)\n",
      "Total trace number: 150909\n",
      "Sample number along each trace: 1001\n",
      "Sampling interval along each trace: 0.002 s\n",
      "data arrangement: 269 (number of ensembles) x 561 (trace number per ensemble) x 1001 (sample number per trace)\n",
      "Total trace number: 242136\n",
      "Sample number along each trace: 1001\n",
      "Sampling interval along each trace: 0.002 s\n",
      "data arrangement: 216 (number of ensembles) x 1121 (trace number per ensemble) x 1001 (sample number per trace)\n"
     ]
    }
   ],
   "source": [
    "# load the data head\n",
    "D0 = dataload(fn=blfn)\n",
    "D0n = dataload(fn=blfn2)\n",
    "Dt = dataload(fn=tlfn)\n",
    "Dtn = dataload(fn=tlfn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask dimension\n",
    "DD = (Dt.nx,Dt.ny,Dt.nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the entire 3D data from the three data volume\n",
    "d0,xd0,yd0,td0 = D0.getdata()\n",
    "d0n,xdn,ydn,_ = D0n.getdata()\n",
    "dt,xd,yd,td = Dt.getdata()\n",
    "dtn,xdt,ydt,tdt = Dtn.getdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess d0n and dtn to make them in the same dimension as d0 and dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate d0n to the same dimension as dt(d0)\n",
    "X = np.stack((xd.flatten(),yd.flatten()),axis=1)\n",
    "Xn = np.stack((xdn.flatten(),ydn.flatten()),axis=1)\n",
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(Xn)\n",
    "distances, ind = nbrs.kneighbors(X)\n",
    "sub = ind2sub(xdn.shape,ind)\n",
    "d0i = d0n[sub[0],sub[1],:]\n",
    "d0i = np.reshape(d0i,d0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate dtn the same dimension as dt(d0)\n",
    "# downsample along xline direction\n",
    "dtn1 = np.pad(dtn[:,1:-3:2,:],((0,0),(2,0),(0,0)),'edge')\n",
    "# calculate the coefficient for linear interpolation\n",
    "xdh,xdth = xd[:,0],xdt[:,0]\n",
    "X = np.stack((xdh,np.zeros(Dt.nx)),axis=1)\n",
    "Xt = np.stack((xdth,np.zeros(Dtn.nx)),axis=1)\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(Xt)\n",
    "distances, ind = nbrs.kneighbors(X)\n",
    "coe = np.flip(distances,axis=1)/np.expand_dims(np.sum(distances,axis=1),1)\n",
    "# linear interpolate along inline direction\n",
    "dti = np.zeros(DD,dtype=np.float32)\n",
    "for i in range(Dt.nx):\n",
    "    dti[i,:,:] = dtn1[ind[i,0],:,:]*coe[i,0]+dtn1[ind[i,1],:,:]*coe[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "# normalize d0,dt,d0i,dti\n",
    "d0 = (d0-np.mean(d0))/(np.std(d0)+eps)\n",
    "d0i = (d0i-np.mean(d0i))/(np.std(d0i)+eps)\n",
    "dt = (dt-np.mean(dt))/(np.std(dt)+eps)\n",
    "dti = (dti-np.mean(dti))/(np.std(dti)+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 3D patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the reference CO2 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin CO2 mask\n",
    "masks = np.fromfile(f'{mkfn}',dtype=np.float32)\n",
    "masks = np.reshape(masks,DD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define slice labels and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D vs 3D test: define x and y slices as interpreted in the 3D masks\n",
    "inline_itp = np.array([60,80,100,120,130,140,150,160,180,200])\n",
    "xline_itp = np.array([100,150,180,210,240,270,300,330,360,390,420,450,500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noitp = 10\n",
    "mask_itp = np.zeros_like(masks,dtype=np.float32)+noitp\n",
    "for i,j in product(inline_itp,xline_itp):\n",
    "    mask_itp[i,:,:] = masks[i,:,:]\n",
    "    mask_itp[:,j,:] = masks[:,j,:]\n",
    "weight = mask_itp!=noitp\n",
    "mask_itp *= weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wether to use slice interpretation\n",
    "bool_sliceitp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in inline_itp:\\n    plt.imshow(mask_itp[i,:,:].T,vmin=0,vmax=1)\\n    plt.show()\\nfor j in xline_itp:\\n    plt.imshow(mask_itp[:,j,:].T,vmin=0,vmax=1)\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the selected slices\n",
    "r'''\n",
    "for i in inline_itp:\n",
    "    plt.imshow(mask_itp[i,:,:].T,vmin=0,vmax=1)\n",
    "    plt.show()\n",
    "for j in xline_itp:\n",
    "    plt.imshow(mask_itp[:,j,:].T,vmin=0,vmax=1)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the weight in 3D\n",
    "#show3D(np.array(weight,dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy everything from fulllabel training dataset to sparselabel training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = glob.glob(f'{outpath0}/*')\n",
    "for fni in fn:\n",
    "    shutil.copy(fni, f'{outpath}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{outpath}/pm_info.json','r') as read_file:\n",
    "    loaded_pm = json.loads(read_file.read())\n",
    "    Ni,Nx,Nt = loaded_pm['patch_osize']\n",
    "    rs = loaded_pm['patch_nsize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### revise the masks and save corresponding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling center range along x, y, and t directions\n",
    "hNi = Ni//2\n",
    "hNx = Nx//2\n",
    "hNt = Nt//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d resize class\n",
    "RS = resize3d(1,D=rs[0],H=rs[0],W=rs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all training patch information\n",
    "pf = pd.read_csv(f'{outpath}/patch_info_train.csv')\n",
    "pid = pf['Ptch_id']\n",
    "mid = pf['Mask_id']\n",
    "ixt = pf['ct']\n",
    "N = len(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revise the mask patches and add weight patches iteratively for training\n",
    "hNi1 = Ni-hNi\n",
    "hNx1 = Nx-hNx\n",
    "hNt1 = Nt-hNt\n",
    "for i in range(N):\n",
    "    ixti = re.findall(r\"\\d+?\\d*\",ixt[i])\n",
    "    Is = int(ixti[0])\n",
    "    Xs = int(ixti[1])\n",
    "    Ts = int(ixti[2])\n",
    "    # slice the weighted mask\n",
    "    if bool_sliceitp:\n",
    "        M = np.array(mask_itp[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1],dtype=np.float32)\n",
    "        M = torch.tensor(M[::2,::2,::4]).unsqueeze(0).unsqueeze(0).numpy()\n",
    "        #M = RS.resize(torch.tensor(M).unsqueeze(0).unsqueeze(0),NP=True) # 5D: (N=1,C=1,D=64,H=64,W=64)\n",
    "        W = np.array(weight[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1],dtype=np.float32)\n",
    "        W = torch.tensor(W[::2,::2,::4]).unsqueeze(0).unsqueeze(0).numpy()\n",
    "        #W = RS.resize(torch.tensor(W).unsqueeze(0).unsqueeze(0),NP=True) # 5D: (N=1,C=1,D=64,H=64,W=64)\n",
    "    else:\n",
    "        M = np.array(masks[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1],dtype=np.float32)\n",
    "        M = RS.resize(torch.tensor(M).unsqueeze(0).unsqueeze(0),NP=True) # 5D: (N=1,C=1,D=64,H=64,W=64)        \n",
    "    # save the revised mask and weight\n",
    "    M.tofile(f'{outpath}/Mask_{mid[i]}.dat')\n",
    "    if bool_sliceitp:\n",
    "        W.tofile(f'{outpath}/Weight_{mid[i]}.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all training patch information\n",
    "pf = pd.read_csv(f'{outpath}/patch_info_valid.csv')\n",
    "pid = pf['Ptch_id']\n",
    "mid = pf['Mask_id']\n",
    "ixt = pf['ct']\n",
    "N = len(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revise the mask patches and add weight patches iteratively for validation\n",
    "for i in range(N):\n",
    "    ixti = re.findall(r\"\\d+?\\d*\",ixt[i])\n",
    "    Is = int(ixti[0])\n",
    "    Xs = int(ixti[1])\n",
    "    Ts = int(ixti[2])\n",
    "    # slice the weighted mask\n",
    "    if bool_sliceitp:\n",
    "        M = np.array(mask_itp[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1],dtype=np.float32)\n",
    "        M = torch.tensor(M[::2,::2,::4]).unsqueeze(0).unsqueeze(0).numpy()\n",
    "        #M = RS.resize(torch.tensor(M).unsqueeze(0).unsqueeze(0),NP=True) # 5D: (N=1,C=1,D=64,H=64,W=64)\n",
    "        W = np.array(weight[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1],dtype=np.float32)\n",
    "        W = torch.tensor(W[::2,::2,::4]).unsqueeze(0).unsqueeze(0).numpy()\n",
    "        #W = RS.resize(torch.tensor(W).unsqueeze(0).unsqueeze(0),NP=True) # 5D: (N=1,C=1,D=64,H=64,W=64)\n",
    "    else:\n",
    "        M = np.array(masks[Is-hNi:Is+hNi1,Xs-hNx:Xs+hNx1,Ts-hNt:Ts+hNt1],dtype=np.float32)\n",
    "        M = RS.resize(torch.tensor(M).unsqueeze(0).unsqueeze(0),NP=True) # 5D: (N=1,C=1,D=64,H=64,W=64)        \n",
    "    # save the revised mask and weight\n",
    "    M.tofile(f'{outpath}/Mask_{mid[i]}.dat')\n",
    "    if bool_sliceitp:\n",
    "        W.tofile(f'{outpath}/Weight_{mid[i]}.dat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265.883px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
